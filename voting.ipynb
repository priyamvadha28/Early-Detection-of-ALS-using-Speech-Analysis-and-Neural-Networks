{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 978 images belonging to 2 classes.\n",
      "Found 246 images belonging to 2 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.5864 - loss: 0.7406 - val_accuracy: 0.6667 - val_loss: 0.6455 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.6493 - loss: 0.6504 - val_accuracy: 0.6667 - val_loss: 0.6393 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.6515 - loss: 0.6761 - val_accuracy: 0.6667 - val_loss: 0.6396 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.6567 - loss: 0.6485 - val_accuracy: 0.6667 - val_loss: 0.6381 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.6867 - loss: 0.6284 - val_accuracy: 0.6667 - val_loss: 0.6401 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.6511 - loss: 0.6582 - val_accuracy: 0.6667 - val_loss: 0.6423 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.6776 - loss: 0.6363 - val_accuracy: 0.6667 - val_loss: 0.6393 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.6917 - loss: 0.6226 - val_accuracy: 0.6667 - val_loss: 0.6396 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.6473 - loss: 0.6519 - val_accuracy: 0.6667 - val_loss: 0.6400 - learning_rate: 1.0000e-05\n",
      "Epoch 1/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.6244 - loss: 0.7137 - val_accuracy: 0.6220 - val_loss: 0.6522 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.6288 - loss: 0.6770 - val_accuracy: 0.6626 - val_loss: 0.6377 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.6393 - loss: 0.6673 - val_accuracy: 0.6667 - val_loss: 0.6347 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.6154 - loss: 0.6678 - val_accuracy: 0.6626 - val_loss: 0.6251 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.6419 - loss: 0.6482 - val_accuracy: 0.6626 - val_loss: 0.6220 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.6741 - loss: 0.6376 - val_accuracy: 0.6504 - val_loss: 0.6177 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.6194 - loss: 0.6738 - val_accuracy: 0.6626 - val_loss: 0.6140 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.6241 - loss: 0.6296 - val_accuracy: 0.6667 - val_loss: 0.6218 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.6994 - loss: 0.5944 - val_accuracy: 0.6545 - val_loss: 0.6115 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.6516 - loss: 0.6291 - val_accuracy: 0.6545 - val_loss: 0.6111 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.6717 - loss: 0.6281 - val_accuracy: 0.6667 - val_loss: 0.6210 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.6822 - loss: 0.6086 - val_accuracy: 0.6626 - val_loss: 0.6103 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.6261 - loss: 0.6536 - val_accuracy: 0.6667 - val_loss: 0.6295 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.6648 - loss: 0.6408 - val_accuracy: 0.6667 - val_loss: 0.6131 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.6243 - loss: 0.6411 - val_accuracy: 0.6667 - val_loss: 0.6315 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.6808 - loss: 0.6063 - val_accuracy: 0.6667 - val_loss: 0.6221 - learning_rate: 1.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.6796 - loss: 0.6182 - val_accuracy: 0.6667 - val_loss: 0.6163 - learning_rate: 1.0000e-05\n",
      "Epoch 1/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.6185 - loss: 0.6740 - val_accuracy: 0.6667 - val_loss: 0.6374 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - accuracy: 0.6622 - loss: 0.6447 - val_accuracy: 0.6667 - val_loss: 0.6368 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.6667 - loss: 0.6364 - val_accuracy: 0.6667 - val_loss: 0.6367 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.6614 - loss: 0.6437 - val_accuracy: 0.6667 - val_loss: 0.6365 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.6885 - loss: 0.6222 - val_accuracy: 0.6667 - val_loss: 0.6365 - learning_rate: 1.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000024DA7CBD9E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step\n",
      "Confusion Matrix:\n",
      "[[164   0]\n",
      " [ 82   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         als       0.67      1.00      0.80       164\n",
      "     healthy       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.67       246\n",
      "   macro avg       0.33      0.50      0.40       246\n",
      "weighted avg       0.44      0.67      0.53       246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, DenseNet121, EfficientNetB0\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Define ImageDataGenerators for training and validation with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    brightness_range=[0.2, 1.5]\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\Priyamvadha Pradeep\\Desktop\\FYP\\CNN\\New Models\\train\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # Two classes: ALS and Healthy\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\Priyamvadha Pradeep\\Desktop\\FYP\\CNN\\New Models\\validate\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Define the models (ResNet50, DenseNet121, EfficientNetB0)\n",
    "def create_resnet50_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_densenet121_model():\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_efficientnet_model():\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize models\n",
    "resnet50_model = create_resnet50_model()\n",
    "densenet121_model = create_densenet121_model()\n",
    "efficientnet_model = create_efficientnet_model()\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train models\n",
    "history_resnet50 = resnet50_model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "history_densenet121 = densenet121_model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "history_efficientnet = efficientnet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Get predictions from all models\n",
    "y_pred_resnet50 = resnet50_model.predict(val_generator)\n",
    "y_pred_densenet121 = densenet121_model.predict(val_generator)\n",
    "y_pred_efficientnet = efficientnet_model.predict(val_generator)\n",
    "\n",
    "# Combine the predictions using soft voting (average the probabilities)\n",
    "y_pred_avg = (y_pred_resnet50 + y_pred_densenet121 + y_pred_efficientnet) / 3\n",
    "y_pred_avg = (y_pred_avg > 0.5).astype(int)  # Convert probabilities to class labels\n",
    "\n",
    "# Get true labels\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_avg)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_true, y_pred_avg, target_names=train_generator.class_indices.keys())\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 Accuracy: 0.6667\n",
      "DenseNet121 Accuracy: 0.6789\n",
      "EfficientNetB0 Accuracy: 0.6667\n",
      "Ensemble Model Accuracy (Soft Voting): 0.6667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate and print accuracies for each individual model\n",
    "accuracy_resnet50 = accuracy_score(y_true, (y_pred_resnet50 > 0.5).astype(int))\n",
    "accuracy_densenet121 = accuracy_score(y_true, (y_pred_densenet121 > 0.5).astype(int))\n",
    "accuracy_efficientnet = accuracy_score(y_true, (y_pred_efficientnet > 0.5).astype(int))\n",
    "\n",
    "# Calculate and print accuracy for the ensemble model\n",
    "accuracy_avg = accuracy_score(y_true, y_pred_avg)\n",
    "\n",
    "# Print accuracies\n",
    "print(f\"ResNet50 Accuracy: {accuracy_resnet50:.4f}\")\n",
    "print(f\"DenseNet121 Accuracy: {accuracy_densenet121:.4f}\")\n",
    "print(f\"EfficientNetB0 Accuracy: {accuracy_efficientnet:.4f}\")\n",
    "print(f\"Ensemble Model Accuracy (Soft Voting): {accuracy_avg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
