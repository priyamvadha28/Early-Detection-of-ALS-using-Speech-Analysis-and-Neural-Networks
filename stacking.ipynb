{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 978 images belonging to 2 classes.\n",
      "Found 246 images belonging to 2 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.5130 - loss: 0.8210 - val_accuracy: 0.6667 - val_loss: 0.6885\n",
      "Epoch 2/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.6220 - loss: 0.6875 - val_accuracy: 0.6667 - val_loss: 0.6679\n",
      "Epoch 3/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.6482 - loss: 0.6532 - val_accuracy: 0.6667 - val_loss: 0.6522\n",
      "Epoch 4/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.6119 - loss: 0.6682 - val_accuracy: 0.6667 - val_loss: 0.6712\n",
      "Epoch 5/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 3s/step - accuracy: 0.6511 - loss: 0.6424 - val_accuracy: 0.6667 - val_loss: 0.6537\n",
      "Epoch 6/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3s/step - accuracy: 0.6830 - loss: 0.6249 - val_accuracy: 0.6667 - val_loss: 0.6443\n",
      "Epoch 7/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2s/step - accuracy: 0.6468 - loss: 0.6466 - val_accuracy: 0.6667 - val_loss: 0.6572\n",
      "Epoch 8/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.6485 - loss: 0.6532 - val_accuracy: 0.6667 - val_loss: 0.6477\n",
      "Epoch 9/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.6253 - loss: 0.6646 - val_accuracy: 0.6667 - val_loss: 0.6676\n",
      "Epoch 10/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.6437 - loss: 0.6726 - val_accuracy: 0.6667 - val_loss: 0.6613\n",
      "Epoch 11/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.6854 - loss: 0.6355 - val_accuracy: 0.6667 - val_loss: 0.6406\n",
      "Epoch 12/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.6724 - loss: 0.6383 - val_accuracy: 0.6667 - val_loss: 0.6580\n",
      "Epoch 13/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.6699 - loss: 0.6519 - val_accuracy: 0.6667 - val_loss: 0.6433\n",
      "Epoch 14/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.6860 - loss: 0.6356 - val_accuracy: 0.6667 - val_loss: 0.6397\n",
      "Epoch 15/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.6204 - loss: 0.6625 - val_accuracy: 0.6667 - val_loss: 0.6921\n",
      "Epoch 16/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.6446 - loss: 0.6684 - val_accuracy: 0.6667 - val_loss: 0.6600\n",
      "Epoch 17/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.6520 - loss: 0.6511 - val_accuracy: 0.6667 - val_loss: 0.6763\n",
      "Epoch 18/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.7009 - loss: 0.6307 - val_accuracy: 0.6667 - val_loss: 0.6376\n",
      "Epoch 19/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.6685 - loss: 0.6500 - val_accuracy: 0.6667 - val_loss: 0.6469\n",
      "Epoch 20/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.6653 - loss: 0.6458 - val_accuracy: 0.6667 - val_loss: 0.6577\n",
      "Epoch 21/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.6942 - loss: 0.6286 - val_accuracy: 0.6667 - val_loss: 0.6506\n",
      "Epoch 22/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.6355 - loss: 0.6562 - val_accuracy: 0.6667 - val_loss: 0.6585\n",
      "Epoch 23/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.6814 - loss: 0.6320 - val_accuracy: 0.6667 - val_loss: 0.6469\n",
      "Epoch 24/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.6615 - loss: 0.6529 - val_accuracy: 0.6667 - val_loss: 0.6414\n",
      "Epoch 25/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.6640 - loss: 0.6475 - val_accuracy: 0.6667 - val_loss: 0.6433\n",
      "Epoch 26/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.6417 - loss: 0.6587 - val_accuracy: 0.6667 - val_loss: 0.6548\n",
      "Epoch 27/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.6752 - loss: 0.6395 - val_accuracy: 0.6667 - val_loss: 0.6388\n",
      "Epoch 28/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.6633 - loss: 0.6551 - val_accuracy: 0.6667 - val_loss: 0.6386\n",
      "Epoch 29/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.6401 - loss: 0.6586 - val_accuracy: 0.6667 - val_loss: 0.6490\n",
      "Epoch 30/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.6460 - loss: 0.6622 - val_accuracy: 0.6667 - val_loss: 0.6477\n",
      "Epoch 1/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3s/step - accuracy: 0.5464 - loss: 0.7865 - val_accuracy: 0.6748 - val_loss: 0.6186\n",
      "Epoch 2/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.6485 - loss: 0.6848 - val_accuracy: 0.6504 - val_loss: 0.6294\n",
      "Epoch 3/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.5748 - loss: 0.7126 - val_accuracy: 0.6667 - val_loss: 0.6221\n",
      "Epoch 4/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.6364 - loss: 0.6785 - val_accuracy: 0.6667 - val_loss: 0.6138\n",
      "Epoch 5/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.6849 - loss: 0.6077 - val_accuracy: 0.6870 - val_loss: 0.6134\n",
      "Epoch 6/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.6313 - loss: 0.6460 - val_accuracy: 0.6667 - val_loss: 0.6170\n",
      "Epoch 7/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.6613 - loss: 0.6339 - val_accuracy: 0.6667 - val_loss: 0.6257\n",
      "Epoch 8/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.6247 - loss: 0.6622 - val_accuracy: 0.6667 - val_loss: 0.6221\n",
      "Epoch 9/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.6306 - loss: 0.6730 - val_accuracy: 0.6667 - val_loss: 0.6078\n",
      "Epoch 10/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.6658 - loss: 0.6338 - val_accuracy: 0.6748 - val_loss: 0.6034\n",
      "Epoch 11/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.6224 - loss: 0.6600 - val_accuracy: 0.6667 - val_loss: 0.6050\n",
      "Epoch 12/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.6575 - loss: 0.6193 - val_accuracy: 0.6667 - val_loss: 0.6067\n",
      "Epoch 13/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.6113 - loss: 0.6686 - val_accuracy: 0.6667 - val_loss: 0.6295\n",
      "Epoch 14/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.6281 - loss: 0.6592 - val_accuracy: 0.6667 - val_loss: 0.6161\n",
      "Epoch 15/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.6366 - loss: 0.6446 - val_accuracy: 0.6667 - val_loss: 0.6151\n",
      "Epoch 16/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.6530 - loss: 0.6326 - val_accuracy: 0.6626 - val_loss: 0.6014\n",
      "Epoch 17/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.6426 - loss: 0.6367 - val_accuracy: 0.6667 - val_loss: 0.6027\n",
      "Epoch 18/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.6256 - loss: 0.6469 - val_accuracy: 0.6667 - val_loss: 0.6397\n",
      "Epoch 19/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.6730 - loss: 0.6202 - val_accuracy: 0.6667 - val_loss: 0.6192\n",
      "Epoch 20/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.6556 - loss: 0.6205 - val_accuracy: 0.6667 - val_loss: 0.6303\n",
      "Epoch 21/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.6651 - loss: 0.6044 - val_accuracy: 0.6667 - val_loss: 0.6153\n",
      "Epoch 22/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.6873 - loss: 0.6124 - val_accuracy: 0.6667 - val_loss: 0.6023\n",
      "Epoch 23/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.6264 - loss: 0.6424 - val_accuracy: 0.6667 - val_loss: 0.6219\n",
      "Epoch 24/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.6675 - loss: 0.6172 - val_accuracy: 0.6667 - val_loss: 0.6223\n",
      "Epoch 25/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.6406 - loss: 0.6218 - val_accuracy: 0.6626 - val_loss: 0.6077\n",
      "Epoch 26/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.6376 - loss: 0.6216 - val_accuracy: 0.6626 - val_loss: 0.6122\n",
      "Epoch 27/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.6515 - loss: 0.6301 - val_accuracy: 0.6626 - val_loss: 0.6064\n",
      "Epoch 28/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.6521 - loss: 0.6297 - val_accuracy: 0.6626 - val_loss: 0.6190\n",
      "Epoch 29/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.6363 - loss: 0.6372 - val_accuracy: 0.6626 - val_loss: 0.6197\n",
      "Epoch 30/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.6376 - loss: 0.6455 - val_accuracy: 0.6585 - val_loss: 0.6085\n",
      "Epoch 1/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.5977 - loss: 0.6726 - val_accuracy: 0.6667 - val_loss: 0.6375\n",
      "Epoch 2/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.6946 - loss: 0.6236 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 3/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.6715 - loss: 0.6361 - val_accuracy: 0.6667 - val_loss: 0.6366\n",
      "Epoch 4/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.6524 - loss: 0.6463 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 5/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.6783 - loss: 0.6294 - val_accuracy: 0.6667 - val_loss: 0.6366\n",
      "Epoch 6/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - accuracy: 0.6679 - loss: 0.6323 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 7/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - accuracy: 0.6639 - loss: 0.6411 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 8/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.6685 - loss: 0.6365 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 9/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.6699 - loss: 0.6386 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 10/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - accuracy: 0.6768 - loss: 0.6339 - val_accuracy: 0.6667 - val_loss: 0.6366\n",
      "Epoch 11/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.6525 - loss: 0.6467 - val_accuracy: 0.6667 - val_loss: 0.6366\n",
      "Epoch 12/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.6827 - loss: 0.6262 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 13/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.6693 - loss: 0.6357 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 14/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.6659 - loss: 0.6389 - val_accuracy: 0.6667 - val_loss: 0.6366\n",
      "Epoch 15/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.6660 - loss: 0.6382 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 16/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.6401 - loss: 0.6573 - val_accuracy: 0.6667 - val_loss: 0.6368\n",
      "Epoch 17/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.6795 - loss: 0.6290 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 18/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.6454 - loss: 0.6508 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 19/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.6569 - loss: 0.6444 - val_accuracy: 0.6667 - val_loss: 0.6366\n",
      "Epoch 20/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.6524 - loss: 0.6448 - val_accuracy: 0.6667 - val_loss: 0.6367\n",
      "Epoch 21/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.6642 - loss: 0.6377 - val_accuracy: 0.6667 - val_loss: 0.6370\n",
      "Epoch 22/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.6879 - loss: 0.6200 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 23/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.6436 - loss: 0.6514 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 24/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.6703 - loss: 0.6321 - val_accuracy: 0.6667 - val_loss: 0.6369\n",
      "Epoch 25/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.6634 - loss: 0.6395 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 26/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.6642 - loss: 0.6385 - val_accuracy: 0.6667 - val_loss: 0.6366\n",
      "Epoch 27/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.6717 - loss: 0.6333 - val_accuracy: 0.6667 - val_loss: 0.6368\n",
      "Epoch 28/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.6717 - loss: 0.6344 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 29/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.6894 - loss: 0.6211 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "Epoch 30/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.6805 - loss: 0.6287 - val_accuracy: 0.6667 - val_loss: 0.6365\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000024EA793FD80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step \n",
      "Confusion Matrix:\n",
      "[[29  0]\n",
      " [21  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         als       0.58      1.00      0.73        29\n",
      "     healthy       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.58        50\n",
      "   macro avg       0.29      0.50      0.37        50\n",
      "weighted avg       0.34      0.58      0.43        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert predictions to binary classes (0 or 1) for individual models\n",
    "y_pred_resnet50 = (pred_resnet50 > 0.5).astype(int).flatten()\n",
    "y_pred_densenet121 = (pred_densenet121 > 0.5).astype(int).flatten()\n",
    "y_pred_efficientnet = (pred_efficientnet > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate individual model accuracies\n",
    "accuracy_resnet50 = accuracy_score(y_true, y_pred_resnet50)\n",
    "accuracy_densenet121 = accuracy_score(y_true, y_pred_densenet121)\n",
    "accuracy_efficientnet = accuracy_score(y_true, y_pred_efficientnet)\n",
    "\n",
    "# Print individual model accuracies\n",
    "print(f\"ResNet50 Model Accuracy: {accuracy_resnet50:.4f}\")\n",
    "print(f\"DenseNet121 Model Accuracy: {accuracy_densenet121:.4f}\")\n",
    "print(f\"EfficientNetB0 Model Accuracy: {accuracy_efficientnet:.4f}\")\n",
    "\n",
    "# Calculate and print meta-model accuracy\n",
    "accuracy_meta_model = accuracy_score(y_test, y_pred_meta)\n",
    "print(f\"Meta-Model (Stacked Ensemble) Accuracy: {accuracy_meta_model:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 Model Accuracy: 0.6667\n",
      "DenseNet121 Model Accuracy: 0.6667\n",
      "EfficientNetB0 Model Accuracy: 0.6667\n",
      "Meta-Model (Stacked Ensemble) Accuracy: 0.5800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert predictions to binary classes (0 or 1) for individual models\n",
    "y_pred_resnet50 = (pred_resnet50 > 0.5).astype(int).flatten()\n",
    "y_pred_densenet121 = (pred_densenet121 > 0.5).astype(int).flatten()\n",
    "y_pred_efficientnet = (pred_efficientnet > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate individual model accuracies\n",
    "accuracy_resnet50 = accuracy_score(y_true, y_pred_resnet50)\n",
    "accuracy_densenet121 = accuracy_score(y_true, y_pred_densenet121)\n",
    "accuracy_efficientnet = accuracy_score(y_true, y_pred_efficientnet)\n",
    "\n",
    "# Print individual model accuracies\n",
    "print(f\"ResNet50 Model Accuracy: {accuracy_resnet50:.4f}\")\n",
    "print(f\"DenseNet121 Model Accuracy: {accuracy_densenet121:.4f}\")\n",
    "print(f\"EfficientNetB0 Model Accuracy: {accuracy_efficientnet:.4f}\")\n",
    "\n",
    "# Calculate and print meta-model accuracy\n",
    "accuracy_meta_model = accuracy_score(y_test, y_pred_meta)\n",
    "print(f\"Meta-Model (Stacked Ensemble) Accuracy: {accuracy_meta_model:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
