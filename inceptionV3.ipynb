{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 978 images belonging to 2 classes.\n",
      "Found 246 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.6050 - loss: 0.7178 - val_accuracy: 0.6667 - val_loss: 0.6416 - learning_rate: 1.0000e-04\n",
      "Epoch 2/40\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.6652 - loss: 0.6439 - val_accuracy: 0.6667 - val_loss: 0.6345 - learning_rate: 1.0000e-04\n",
      "Epoch 3/40\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.6380 - loss: 0.6627 - val_accuracy: 0.6707 - val_loss: 0.6322 - learning_rate: 1.0000e-04\n",
      "Epoch 4/40\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.6374 - loss: 0.6285 - val_accuracy: 0.6748 - val_loss: 0.6327 - learning_rate: 1.0000e-04\n",
      "Epoch 5/40\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - accuracy: 0.6623 - loss: 0.6405 - val_accuracy: 0.6748 - val_loss: 0.6309 - learning_rate: 1.0000e-04\n",
      "Epoch 6/40\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.6414 - loss: 0.6596 - val_accuracy: 0.6748 - val_loss: 0.6273 - learning_rate: 1.0000e-04\n",
      "Epoch 7/40\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.6208 - loss: 0.6515 - val_accuracy: 0.6707 - val_loss: 0.6277 - learning_rate: 1.0000e-04\n",
      "Epoch 8/40\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.6556 - loss: 0.6303 - val_accuracy: 0.6707 - val_loss: 0.6244 - learning_rate: 1.0000e-04\n",
      "Epoch 9/40\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.6622 - loss: 0.6283 - val_accuracy: 0.6789 - val_loss: 0.6262 - learning_rate: 1.0000e-04\n",
      "Epoch 10/40\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.6938 - loss: 0.6062 - val_accuracy: 0.6707 - val_loss: 0.6305 - learning_rate: 1.0000e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.6670 - loss: 0.6036 - val_accuracy: 0.6423 - val_loss: 0.6371 - learning_rate: 1.0000e-04\n",
      "Epoch 12/40\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.6518 - loss: 0.6081 - val_accuracy: 0.6707 - val_loss: 0.6303 - learning_rate: 1.0000e-05\n",
      "Epoch 13/40\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.6669 - loss: 0.6131 - val_accuracy: 0.6789 - val_loss: 0.6288 - learning_rate: 1.0000e-05\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.7018 - loss: 0.6061\n",
      "Validation Loss: 0.6243510246276855\n",
      "Validation Accuracy: 0.6707317233085632\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step\n",
      "Confusion Matrix:\n",
      "[[160   4]\n",
      " [ 81   1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         als       0.66      0.98      0.79       164\n",
      "     healthy       0.20      0.01      0.02        82\n",
      "\n",
      "    accuracy                           0.65       246\n",
      "   macro avg       0.43      0.49      0.41       246\n",
      "weighted avg       0.51      0.65      0.53       246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Define ImageDataGenerators for training and validation with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    brightness_range=[0.2, 1.5]\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\Priyamvadha Pradeep\\Desktop\\FYP\\CNN\\New Models\\train\",  # Replace with your train directory path\n",
    "    target_size=(299, 299),  # InceptionV3 input size\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # Two classes: ALS and Healthy\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\Priyamvadha Pradeep\\Desktop\\FYP\\CNN\\New Models\\validate\",  # Replace with your validation directory path\n",
    "    target_size=(299, 299),  # InceptionV3 input size\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Load pre-trained InceptionV3 model with ImageNet weights (not including the top layers)\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create the model by adding custom layers on top of the base model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())  # For dimensionality reduction\n",
    "model.add(Dropout(0.5))  # Add dropout to reduce overfitting\n",
    "model.add(Dense(256, activation='relu'))  # Dense layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification output\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=40,  # You can adjust this number\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Get predictions for confusion matrix\n",
    "y_pred = model.predict(val_generator)\n",
    "y_pred = (y_pred > 0.5)  # Convert probabilities to class labels\n",
    "\n",
    "# True labels\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_true, y_pred, target_names=train_generator.class_indices.keys())\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
