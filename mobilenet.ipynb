{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 978 images belonging to 2 classes.\n",
      "Found 246 images belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - accuracy: 0.5133 - loss: 0.9432 - val_accuracy: 0.6667 - val_loss: 0.6304 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.5987 - loss: 0.7945 - val_accuracy: 0.6667 - val_loss: 0.6039 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.6117 - loss: 0.7503 - val_accuracy: 0.6667 - val_loss: 0.6029 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.6279 - loss: 0.6811 - val_accuracy: 0.6789 - val_loss: 0.6094 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.5894 - loss: 0.7583 - val_accuracy: 0.6748 - val_loss: 0.6049 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.5901 - loss: 0.7294 - val_accuracy: 0.6667 - val_loss: 0.6009 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.5742 - loss: 0.7521 - val_accuracy: 0.6789 - val_loss: 0.6029 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.6349 - loss: 0.7156 - val_accuracy: 0.6748 - val_loss: 0.6048 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.6161 - loss: 0.6854 - val_accuracy: 0.6829 - val_loss: 0.6041 - learning_rate: 1.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.6374 - loss: 0.6775 - val_accuracy: 0.6789 - val_loss: 0.6046 - learning_rate: 1.0000e-05\n",
      "Epoch 1/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - accuracy: 0.6283 - loss: 0.9110 - val_accuracy: 0.6707 - val_loss: 0.6099 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.6408 - loss: 0.7493 - val_accuracy: 0.6341 - val_loss: 0.6207 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.6348 - loss: 0.6909 - val_accuracy: 0.5894 - val_loss: 0.6307 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.5992 - loss: 0.7513 - val_accuracy: 0.5935 - val_loss: 0.6397 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.6280 - loss: 0.6850 - val_accuracy: 0.6016 - val_loss: 0.6381 - learning_rate: 1.0000e-06\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 739ms/step - accuracy: 0.6190 - loss: 0.6359\n",
      "Validation Loss: 0.609931468963623\n",
      "Validation Accuracy: 0.6707317233085632\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 855ms/step\n",
      "Confusion Matrix:\n",
      "[[141  23]\n",
      " [ 70  12]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         als       0.67      0.86      0.75       164\n",
      "     healthy       0.34      0.15      0.21        82\n",
      "\n",
      "    accuracy                           0.62       246\n",
      "   macro avg       0.51      0.50      0.48       246\n",
      "weighted avg       0.56      0.62      0.57       246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Define ImageDataGenerators for training and validation with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    brightness_range=[0.2, 1.5]\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\Priyamvadha Pradeep\\Desktop\\FYP\\CNN\\New Models\\train\",\n",
    "    target_size=(224, 224),  # MobileNetV2 input size\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # Binary classification: ALS and Healthy\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\Priyamvadha Pradeep\\Desktop\\FYP\\CNN\\New Models\\validate\",\n",
    "    target_size=(224, 224),  # MobileNetV2 input size\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Load pre-trained MobileNetV2 model with ImageNet weights (not including the top layers)\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model initially\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create the model by adding custom layers on top of the base model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())  # For dimensionality reduction\n",
    "model.add(Dropout(0.5))  # Add dropout to reduce overfitting\n",
    "model.add(Dense(256, activation='relu'))  # Dense layer\n",
    "model.add(Dropout(0.5))  # Dropout\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification output\n",
    "\n",
    "# Compile the model with a lower learning rate to start\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model with the base model frozen\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Fine-tuning after 10 epochs can be adjusted\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Unfreeze the last few layers of the base model for fine-tuning\n",
    "for layer in base_model.layers[-30:]:  # Unfreeze the last 30 layers (you can adjust this number)\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile the model to apply the fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with fine-tuned layers\n",
    "fine_tune_history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,  # Continue training for more epochs\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Get predictions for confusion matrix\n",
    "y_pred = model.predict(val_generator)\n",
    "y_pred = (y_pred > 0.5)  # Convert probabilities to class labels\n",
    "\n",
    "# True labels\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_true, y_pred, target_names=train_generator.class_indices.keys())\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
