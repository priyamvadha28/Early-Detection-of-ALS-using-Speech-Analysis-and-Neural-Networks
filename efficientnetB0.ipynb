{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 978 images belonging to 2 classes.\n",
      "Found 246 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 3s/step - accuracy: 0.6318 - loss: 0.6732 - val_accuracy: 0.6667 - val_loss: 0.6416 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.6699 - loss: 0.6395 - val_accuracy: 0.6667 - val_loss: 0.6371 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - accuracy: 0.6857 - loss: 0.6232 - val_accuracy: 0.6667 - val_loss: 0.6365 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - accuracy: 0.6563 - loss: 0.6496 - val_accuracy: 0.6667 - val_loss: 0.6366 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.6775 - loss: 0.6290 - val_accuracy: 0.6667 - val_loss: 0.6365 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.6697 - loss: 0.6341 - val_accuracy: 0.6667 - val_loss: 0.6368 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.6442 - loss: 0.6512 - val_accuracy: 0.6667 - val_loss: 0.6368 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.6379 - loss: 0.6528 - val_accuracy: 0.6667 - val_loss: 0.6368 - learning_rate: 1.0000e-05\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 991ms/step - accuracy: 0.6620 - loss: 0.6398\n",
      "Validation Loss: 0.6365396976470947\n",
      "Validation Accuracy: 0.6666666865348816\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step \n",
      "Confusion Matrix:\n",
      "[[164   0]\n",
      " [ 82   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         als       0.67      1.00      0.80       164\n",
      "     healthy       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.67       246\n",
      "   macro avg       0.33      0.50      0.40       246\n",
      "weighted avg       0.44      0.67      0.53       246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Priyamvadha Pradeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define ImageDataGenerators for training and validation with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    brightness_range=[0.2, 1.5]\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\Priyamvadha Pradeep\\Desktop\\FYP\\CNN\\New Models\\train\",\n",
    "    target_size=(224, 224),  # EfficientNetB0 input size\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # Since you have two classes: ALS and Healthy\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\Priyamvadha Pradeep\\Desktop\\FYP\\CNN\\New Models\\validate\",\n",
    "    target_size=(224, 224),  # EfficientNetB0 input size\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Load pre-trained EfficientNetB0 model with ImageNet weights (not including the top layers)\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create the model by adding custom layers on top of the base model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())  # For dimensionality reduction\n",
    "model.add(Dropout(0.5))  # Add dropout to reduce overfitting\n",
    "model.add(Dense(256, activation='relu'))  # Dense layer\n",
    "model.add(Dropout(0.5))  # Dropout\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification output\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,  # You can adjust this number\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Get predictions for confusion matrix\n",
    "y_pred = model.predict(val_generator)\n",
    "y_pred = (y_pred > 0.5)  # Convert probabilities to class labels\n",
    "\n",
    "# True labels\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_true, y_pred, target_names=train_generator.class_indices.keys())\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
